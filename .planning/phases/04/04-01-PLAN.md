---
phase: 04-docker-settings
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/config.py
  - backend/spa.py
  - backend/main.py
  - backend/db/database.py
  - backend/db/migrations/env.py
  - backend/requirements.txt
  - data/db/.gitkeep
  - Dockerfile
  - docker-compose.yml
  - entrypoint.sh
  - .dockerignore
  - .env.example
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "User can run `docker compose up` on a fresh machine and access the app in a browser"
    - "User's contracts, reservations, and point balances survive `docker compose down && docker compose up`"
    - "User can change port and database path via .env file without editing any code"
    - "App works out of the box with pre-loaded 2026 point chart data"
    - "Alembic migrations run automatically on container startup"
  artifacts:
    - path: "Dockerfile"
      provides: "Multi-stage build (node:22-slim -> python:3.12-slim)"
      contains: "FROM node:22-slim"
    - path: "docker-compose.yml"
      provides: "Single-service compose with named volume for SQLite directory"
      contains: "dvc-data:/app/data/db"
    - path: "entrypoint.sh"
      provides: "Migration runner + uvicorn startup"
      contains: "alembic upgrade head"
    - path: "backend/config.py"
      provides: "Pydantic BaseSettings for env config"
      contains: "class Settings"
    - path: "backend/spa.py"
      provides: "SPAStaticFiles subclass for React SPA serving"
      contains: "class SPAStaticFiles"
    - path: ".env.example"
      provides: "Documented env var template"
      contains: "PORT"
    - path: ".dockerignore"
      provides: "Build context exclusions"
      contains: "node_modules"
  key_links:
    - from: "docker-compose.yml"
      to: "Dockerfile"
      via: "build context"
      pattern: "build:\\s*\\."
    - from: "docker-compose.yml"
      to: ".env"
      via: "env_file directive"
      pattern: "env_file"
    - from: "entrypoint.sh"
      to: "alembic.ini"
      via: "alembic upgrade head command"
      pattern: "alembic upgrade head"
    - from: "backend/main.py"
      to: "backend/spa.py"
      via: "SPA mount at / (LAST, after all routers)"
      pattern: "app\\.mount.*SPAStaticFiles"
    - from: "backend/main.py"
      to: "backend/config.py"
      via: "get_settings() for CORS config"
      pattern: "get_settings"
    - from: "backend/db/migrations/env.py"
      to: "DATABASE_URL env var"
      via: "config.set_main_option override"
      pattern: "set_main_option.*sqlalchemy\\.url"
    - from: "backend/db/database.py"
      to: "backend/config.py"
      via: "Settings.database_url instead of direct os.getenv"
      pattern: "get_settings"
---

<objective>
Docker infrastructure and backend configuration for single-command self-hosting.

Purpose: Enable any user with Docker to run `docker compose up` and have the full DVC Dashboard running with persistent data, configurable settings, and automatic database migrations. This is the foundation for sharing the app.

Output: Working Docker container serving FastAPI + React SPA, with SQLite persistence via named volume, Alembic auto-migrations on startup, and configurable CORS/port/database via .env file.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04/04-RESEARCH.md
@backend/main.py
@backend/db/database.py
@backend/db/migrations/env.py
@backend/requirements.txt
@alembic.ini
@.gitignore
</context>

<tasks>

<task type="auto">
  <name>Task 1: Backend configuration layer (config.py, spa.py, modified main.py, database.py, env.py, requirements.txt)</name>
  <files>
    backend/config.py
    backend/spa.py
    backend/main.py
    backend/db/database.py
    backend/db/migrations/env.py
    backend/requirements.txt
  </files>
  <action>
    **Create `backend/config.py`** -- Pydantic BaseSettings with env var configuration:
    ```python
    from functools import lru_cache
    from pydantic_settings import BaseSettings, SettingsConfigDict

    class Settings(BaseSettings):
        database_url: str = "sqlite+aiosqlite:///./data/db/dvc.db"
        cors_origins: str = "http://localhost:5173"
        port: int = 8000
        host: str = "0.0.0.0"

        model_config = SettingsConfigDict(env_file=".env", env_file_encoding="utf-8")

    @lru_cache
    def get_settings() -> Settings:
        return Settings()
    ```
    Note: Default `database_url` points to `./data/db/dvc.db` (the Docker volume mount path). The `cors_origins` default is the Vite dev server for local development; Docker overrides via env or uses `*`.

    **Create `backend/spa.py`** -- SPAStaticFiles subclass for React SPA catch-all:
    ```python
    from fastapi.staticfiles import StaticFiles
    from starlette.exceptions import HTTPException as StarletteHTTPException

    class SPAStaticFiles(StaticFiles):
        async def get_response(self, path: str, scope):
            try:
                return await super().get_response(path, scope)
            except StarletteHTTPException as ex:
                if ex.status_code == 404:
                    return await super().get_response("index.html", scope)
                raise
    ```

    **Modify `backend/main.py`** -- Use Settings for CORS, mount SPA LAST:
    - Add imports: `from backend.config import get_settings`, `from backend.spa import SPAStaticFiles`, `from pathlib import Path`
    - Before app creation: `settings = get_settings()`
    - Replace hardcoded CORS origins `["http://localhost:5173"]` with `settings.cors_origins.split(",") if settings.cors_origins != "*" else ["*"]`
    - Keep ALL existing `app.include_router(...)` calls in their current order (lines 30-35)
    - Keep existing `/api/health` and `/api/resorts` route definitions
    - AFTER all routers and routes (at the very bottom of the file), add SPA mount:
      ```python
      # SPA mount MUST be LAST -- after all API routers and routes
      _spa_dir = Path(__file__).parent.parent / "frontend" / "dist"
      if _spa_dir.exists():
          app.mount("/", SPAStaticFiles(directory=str(_spa_dir), html=True), name="spa")
      ```
    - The `if _spa_dir.exists()` guard allows dev mode without a frontend build.

    **Modify `backend/db/database.py`** -- Use Settings instead of direct os.getenv:
    - Replace `import os` and `DATABASE_URL = os.getenv(...)` with:
      ```python
      from backend.config import get_settings
      DATABASE_URL = get_settings().database_url
      ```
    - Keep everything else (engine, async_session, Base, get_db) unchanged.

    **Modify `backend/db/migrations/env.py`** -- Override URL from DATABASE_URL env var:
    - After `config = context.config` (line 10), add:
      ```python
      import os
      _db_url = os.environ.get("DATABASE_URL")
      if _db_url:
          config.set_main_option("sqlalchemy.url", _db_url)
      ```
    - This ensures Alembic uses the same database as the runtime app (critical for Docker where the DB path differs from alembic.ini default). Use direct `os.environ` here (not Settings) because Alembic env.py runs in a different context than FastAPI.

    **Update `backend/requirements.txt`** -- Add two new dependencies:
    - Add `pydantic-settings>=2.7.0,<3.0.0` after the existing `pydantic` line
    - Add `python-dotenv>=1.0.0,<2.0.0` after `pydantic-settings`
    - Keep all existing dependencies and version pins unchanged.
  </action>
  <verify>
    Run from project root:
    ```bash
    cd /Users/julianamacbook/dvc
    source .venv/bin/activate  # or equivalent
    pip install pydantic-settings python-dotenv
    python -c "from backend.config import get_settings; s = get_settings(); print(f'DB: {s.database_url}, CORS: {s.cors_origins}, Port: {s.port}')"
    python -c "from backend.spa import SPAStaticFiles; print('SPAStaticFiles imported OK')"
    python -c "from backend.main import app; routes = [r.path for r in app.routes if hasattr(r, 'path')]; print('API routes:', routes)"
    ```
    - Settings prints correct defaults
    - SPAStaticFiles imports without error
    - API routes still listed (SPA mount should NOT appear since frontend/dist may not exist locally)
  </verify>
  <done>
    - `backend/config.py` exists with Settings class reading DATABASE_URL, CORS_ORIGINS, PORT, HOST from env
    - `backend/spa.py` exists with SPAStaticFiles catching 404s and serving index.html
    - `backend/main.py` uses Settings for CORS origins and mounts SPA LAST (only if dist exists)
    - `backend/db/database.py` gets DATABASE_URL from Settings (not os.getenv)
    - `backend/db/migrations/env.py` overrides sqlalchemy.url from DATABASE_URL env var
    - `backend/requirements.txt` includes pydantic-settings and python-dotenv
  </done>
</task>

<task type="auto">
  <name>Task 2: Docker files (Dockerfile, docker-compose.yml, entrypoint.sh, .dockerignore, .env.example, .gitignore update)</name>
  <files>
    Dockerfile
    docker-compose.yml
    entrypoint.sh
    .dockerignore
    .env.example
    .gitignore
    data/db/.gitkeep
  </files>
  <action>
    **Create `data/db/.gitkeep`** -- Empty file to ensure the db directory exists in git. This directory will be the Docker volume mount point.

    **Create `Dockerfile`** -- Multi-stage build:
    ```dockerfile
    # Stage 1: Build frontend
    FROM node:22-slim AS frontend-builder
    WORKDIR /frontend
    COPY frontend/package.json frontend/package-lock.json ./
    RUN npm ci
    COPY frontend/ ./
    RUN npm run build

    # Stage 2: Python runtime
    FROM python:3.12-slim
    WORKDIR /app

    # Install Python dependencies first (cache layer)
    COPY backend/requirements.txt ./requirements.txt
    RUN pip install --no-cache-dir -r requirements.txt

    # Copy backend code
    COPY backend/ ./backend/
    COPY alembic.ini ./

    # Copy data (point charts baked into image; db dir for volume mount)
    COPY data/ ./data/

    # Create db directory (volume mount target) if not present
    RUN mkdir -p ./data/db

    # Copy built frontend from stage 1
    COPY --from=frontend-builder /frontend/dist ./frontend/dist

    # Copy entrypoint
    COPY entrypoint.sh ./
    RUN chmod +x entrypoint.sh

    EXPOSE 8000
    ENTRYPOINT ["./entrypoint.sh"]
    ```
    Key points:
    - `COPY data/ ./data/` brings in `data/point_charts/` (polynesian_2026.json, riviera_2026.json, schema.json) and `data/resorts.json` baked into the image (DOCK-05)
    - `mkdir -p ./data/db` ensures the volume mount target exists
    - `COPY backend/requirements.txt` is separate for Docker layer caching
    - `COPY --from=frontend-builder` brings built React assets into the Python image (DOCK-06)

    **Create `entrypoint.sh`** -- Migration runner + uvicorn:
    ```bash
    #!/bin/sh
    set -e

    echo "Running database migrations..."
    alembic upgrade head

    echo "Starting DVC Dashboard on port ${PORT:-8000}..."
    exec uvicorn backend.main:app --host 0.0.0.0 --port "${PORT:-8000}"
    ```
    Key: `exec` replaces the shell process so uvicorn receives SIGTERM directly for clean shutdown.

    **Create `docker-compose.yml`** -- Single service with named volume:
    ```yaml
    services:
      dvc:
        build: .
        ports:
          - "${PORT:-8000}:8000"
        volumes:
          - dvc-data:/app/data/db
        env_file:
          - path: .env
            required: false
        environment:
          - DATABASE_URL=sqlite+aiosqlite:///./data/db/dvc.db
          - CORS_ORIGINS=*
        healthcheck:
          test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health')"]
          interval: 30s
          timeout: 5s
          retries: 3
          start_period: 10s

    volumes:
      dvc-data:
    ```
    Key points:
    - `dvc-data:/app/data/db` mounts the DIRECTORY (not file) for SQLite WAL sidecar support (DOCK-02)
    - `env_file.required: false` allows running without .env file
    - `DATABASE_URL` hardcoded in `environment` ensures consistency (points to volume-mounted dir)
    - `CORS_ORIGINS=*` because in single-container mode, SPA and API share the same origin (but * allows any external tool access too)
    - User can override `PORT` in `.env` to change both the container internal port and the host mapping

    **Create `.dockerignore`**:
    ```
    .git
    .venv
    venv
    .pytest_cache
    __pycache__
    *.pyc
    node_modules
    frontend/dist
    *.db
    *.db-wal
    *.db-shm
    .env
    .planning
    tests
    .DS_Store
    ```

    **Create `.env.example`**:
    ```bash
    # DVC Dashboard Configuration
    # Copy to .env and modify as needed: cp .env.example .env

    # Server port (default: 8000)
    # PORT=8000

    # Database URL (default: SQLite in data/db/ directory)
    # Only change if you know what you're doing
    # DATABASE_URL=sqlite+aiosqlite:///./data/db/dvc.db

    # CORS allowed origins (comma-separated, default: * in Docker)
    # CORS_ORIGINS=http://localhost:5173,http://localhost:8000
    ```

    **Update `.gitignore`** -- Add Docker/DB artifacts:
    - Add these lines at the end, under a `# Docker` comment:
      ```
      # Docker
      data/db/*.db
      data/db/*.db-wal
      data/db/*.db-shm
      ```
    - Keep all existing .gitignore entries unchanged.
  </action>
  <verify>
    Run from project root:
    ```bash
    cd /Users/julianamacbook/dvc
    # Verify all files exist
    ls -la Dockerfile docker-compose.yml entrypoint.sh .dockerignore .env.example data/db/.gitkeep
    # Verify entrypoint is valid shell
    sh -n entrypoint.sh
    # Verify docker-compose.yml syntax
    docker compose config --quiet
    # Build and run (the real test)
    docker compose up --build -d
    sleep 10
    curl -s http://localhost:8000/api/health | python3 -c "import sys,json; d=json.load(sys.stdin); assert d['status']=='ok', f'Health check failed: {d}'; print('Health OK')"
    curl -s http://localhost:8000/api/resorts | python3 -c "import sys,json; d=json.load(sys.stdin); assert len(d)>0, 'No resorts'; print(f'{len(d)} resorts loaded')"
    curl -s http://localhost:8000/api/point-charts | python3 -c "import sys,json; d=json.load(sys.stdin); assert len(d)>0, 'No charts'; print(f'{len(d)} charts loaded')"
    # Verify SPA serves index.html for React routes
    curl -s -o /dev/null -w '%{http_code}' http://localhost:8000/ | grep -q 200 && echo "SPA root OK"
    curl -s -o /dev/null -w '%{http_code}' http://localhost:8000/contracts | grep -q 200 && echo "SPA client route OK"
    # Verify data persistence: create a contract, restart, check it survived
    curl -s -X POST http://localhost:8000/api/contracts -H "Content-Type: application/json" -d '{"home_resort":"polynesian","use_year_month":2,"annual_points":150,"purchase_type":"direct"}' | python3 -c "import sys,json; d=json.load(sys.stdin); print(f'Created contract {d[\"id\"]}')"
    docker compose down
    docker compose up -d
    sleep 10
    curl -s http://localhost:8000/api/contracts | python3 -c "import sys,json; d=json.load(sys.stdin); assert len(d)>0, 'Data did not persist!'; print(f'Persistence OK: {len(d)} contract(s) survived restart')"
    docker compose down
    ```
  </verify>
  <done>
    - `docker compose up --build` succeeds on a machine with Docker installed
    - App accessible at http://localhost:8000 with React SPA rendering
    - API endpoints respond (/api/health, /api/resorts, /api/point-charts)
    - 2026 point chart data loaded (polynesian, riviera) without manual import
    - Data persists across `docker compose down && docker compose up` (contracts, reservations, point balances survive)
    - Port configurable via PORT in .env
    - All six requirements satisfied: DOCK-01 (compose up works), DOCK-02 (data persists), DOCK-03 (.env config), DOCK-04 (auto migrations), DOCK-05 (pre-seeded charts), DOCK-06 (single container serves both)
  </done>
</task>

</tasks>

<verification>
1. `docker compose up --build` completes without errors
2. `curl http://localhost:8000/api/health` returns `{"status": "ok"}`
3. `curl http://localhost:8000/` returns React SPA HTML (not 404)
4. `curl http://localhost:8000/contracts` returns React SPA HTML (client-side routing works)
5. `curl http://localhost:8000/api/contracts` returns JSON (API still works)
6. `curl http://localhost:8000/api/point-charts` returns 2+ charts (pre-seeded data)
7. Create a contract via API, `docker compose down && docker compose up`, contract still exists
8. Change PORT=9000 in .env, `docker compose up` serves on port 9000
</verification>

<success_criteria>
- Fresh `docker compose up` on any Docker-equipped machine results in a working app
- React SPA loads and all client-side routes work (no 404 on page refresh)
- All existing API endpoints remain functional
- Data survives container lifecycle (stop/start/rebuild)
- Configuration via .env works for port and CORS
- 2026 point charts are baked into the image and available immediately
</success_criteria>

<output>
After completion, create `.planning/phases/04/04-01-SUMMARY.md`
</output>
